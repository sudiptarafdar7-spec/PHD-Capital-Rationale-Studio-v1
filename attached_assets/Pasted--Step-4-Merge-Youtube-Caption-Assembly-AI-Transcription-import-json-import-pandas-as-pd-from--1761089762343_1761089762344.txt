# Step 4: Merge Youtube Caption & Assembly AI Transcription
import json
import pandas as pd
from bisect import bisect_right
import os

# helper: convert hh:mm:ss to seconds
def time_to_seconds(t):
    parts = t.split(":")
    parts = [int(x) for x in parts]
    if len(parts) == 3:
        h, m, s = parts
    elif len(parts) == 2:
        h = 0
        m, s = parts
    else:
        raise ValueError("Time must be mm:ss or hh:mm:ss")
    return h*3600 + m*60 + s

# Load CSV with Folder Paths
df = pd.read_csv("input.csv")

for idx, row in df.iterrows():
    folder_path = row["Folder Path"]
    os.makedirs(folder_path, exist_ok=True)

    # --- load AssemblyAI transcript ---
    assembly_file = os.path.join(folder_path, "transcript.csv")
    if not os.path.exists(assembly_file):
        print(f"❌ transcript.csv not found in {folder_path}, skipping...")
        continue

    assembly_df = pd.read_csv(assembly_file)
    assembly_df = assembly_df.rename(columns={
        "Start Time": "Start Time",
        "End Time": "End Time",
        "Speaker": "Speaker",
        "Transcription": "Transcription"
    })
    assembly_df["start_s"] = assembly_df["Start Time"].apply(time_to_seconds)
    assembly_df["end_s"]   = assembly_df["End Time"].apply(time_to_seconds)
    assembly_df = assembly_df.sort_values("start_s").reset_index(drop=True)

    speakers = []
    for _, r in assembly_df.iterrows():
        speakers.append({
            "speaker": r["Speaker"],
            "start": r["start_s"],
            "end": r["end_s"],
            "start_str": r["Start Time"],
            "end_str": r["End Time"],
            "assembly_text": r.get("Transcription", "")
        })

    # --- Parse JSON3 into word-level timestamps ---
    youtube_words = []
    jsonfile = os.path.join(folder_path, "captions.json")
    txtfile = os.path.join(folder_path, "youtube.txt")

    try:
        with open(jsonfile, "r", encoding="utf-8") as f:
            data = json.load(f)
        for ev in data.get("events", []):
            base = ev.get("tStartMs", 0) / 1000.0
            dur_ms = ev.get("dDurationMs", None)
            segs = ev.get("segs", [])
            for seg in segs:
                text = seg.get("utf8")
                if not text or text.strip() == "":
                    continue
                offset_ms = seg.get("tOffsetMs", 0)
                tokens = text.strip().split()
                if not tokens:
                    continue
                if len(tokens) == 1:
                    t = base + offset_ms/1000.0
                    youtube_words.append((t, tokens[0]))
                else:
                    if dur_ms:
                        dur = dur_ms / 1000.0
                        for i, tk in enumerate(tokens):
                            t = base + (i * dur / max(1, len(tokens)))
                            youtube_words.append((t, tk))
                    else:
                        t_base = base + offset_ms/1000.0
                        for i, tk in enumerate(tokens):
                            t = t_base + i * 0.001
                            youtube_words.append((t, tk))
    except FileNotFoundError:
        if os.path.exists(txtfile):
            with open(txtfile, "r", encoding="utf-8") as f:
                for line in f:
                    parts = line.strip().split(" ", 1)
                    if len(parts) == 2:
                        timestamp = parts[0].strip("[]")
                        text = parts[1].strip()
                        start = time_to_seconds(timestamp)
                        for i, tk in enumerate(text.split()):
                            youtube_words.append((start + i*0.001, tk))
        else:
            print(f"❌ Neither youtube.hi.json3 nor youtube.txt found in {folder_path}, skipping...")
            continue

    youtube_words.sort(key=lambda x: x[0])

    if not speakers:
        print(f"❌ No speakers found in {folder_path}, skipping...")
        continue

    # --- Partition timeline between speakers ---
    midpoints = []
    for i in range(len(speakers)-1):
        mid = (speakers[i]["end"] + speakers[i+1]["start"]) / 2.0
        midpoints.append(mid)

    assigned = [[] for _ in speakers]
    for t, token in youtube_words:
        idx = bisect_right(midpoints, t)
        assigned[idx].append((t, token))

    # --- Build final lines ---
    final_lines = []
    for i, sp in enumerate(speakers):
        words = [tok for _, tok in assigned[i]]
        if words:
            merged_text = " ".join(words).strip()
        else:
            merged_text = sp["assembly_text"].strip()
        final_lines.append(f"[{sp['speaker']}] {sp['start_str']} - {sp['end_str']} | {merged_text}")

    # --- Save final transcript in same folder ---
    output_file = os.path.join(folder_path, "final_transcript.txt")
    with open(output_file, "w", encoding="utf-8") as f:
        for L in final_lines:
            f.write(L + "\n")

    print(f"✅ final_transcript.txt written in {folder_path}")
