# Step 13 - Import Stock Chart using Dhan API

import os, sys, json, math, time, subprocess
from datetime import datetime, timedelta, timezone


import pandas as pd
import numpy as np
import requests
import pytz
from dateutil.relativedelta import relativedelta
import matplotlib.pyplot as plt
import mplfinance as mpf

# ---- Constants -----------------------------------------------------------
IST = pytz.timezone("Asia/Kolkata")
BASE = "https://api.dhan.co/v2"

# Paste/replace with your token if needed
DHAN_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpc3MiOiJkaGFuIiwicGFydG5lcklkIjoiIiwiZXhwIjoxNzU5MjE0MjYwLCJ0b2tlbkNvbnN1bWVyVHlwZSI6IlNFTEYiLCJ3ZWJob29rVXJsIjoiIiwiZGhhbkNsaWVudElkIjoiMTEwODMyOTA3NiJ9.ORxEk0aUyEefv_Bi4tmIQGeSk7nDqgd-3KdZtpf3sgQ2uq_Cdh5Pg9PjBw0Z-xhZQ5Vdo671H_TU_pK146_jTQ"

HEADERS = {
    "Content-Type": "application/json",
    "Accept": "application/json",
    "access-token": DHAN_TOKEN
}

# ---- Parsing helpers -----------------------------------------------------
def parse_date(s: str) -> datetime.date:
    """Accept YYYY-MM-DD or DD-MM-YYYY or DD/MM/YYYY"""
    s = str(s).strip()
    for fmt in ("%Y-%m-%d", "%d-%m-%Y", "%d/%m/%Y"):
        try:
            return datetime.strptime(s, fmt).date()
        except ValueError:
            continue
    raise ValueError(f"Unrecognized DATE format: {s!r}")

def parse_time(s: str):
    """Accept HH:MM:SS, HH:MM or HH.MM.SS (as in your CSV)"""
    s = str(s).strip().replace(".", ":")
    for fmt in ("%H:%M:%S", "%H:%M"):
        try:
            dt = datetime.strptime(s, fmt)
            return dt.hour, dt.minute, getattr(dt, "second", 0)
        except ValueError:
            continue
    raise ValueError(f"Unrecognized START TIME format: {s!r}")

# ---- API helpers ---------------------------------------------------------
def _post(path: str, payload: dict, max_retries: int = 4) -> dict:
    """POST with retry on typical transient errors; raises otherwise."""
    for attempt in range(max_retries):
        r = requests.post(f"{BASE}{path}", headers=HEADERS, json=payload, timeout=30)
        if r.ok:
            return r.json()
        if r.status_code in (429, 500, 502, 503, 504):
            # exponential backoff
            time.sleep(2 ** attempt)
            continue
        # hard failure (4xx not covered above)
        r.raise_for_status()
    raise RuntimeError("Max retries exceeded")

def _is_empty_payload(d: dict) -> bool:
    """Detect if Dhan returned an empty arrays payload (no candles)."""
    if not isinstance(d, dict) or not d:
        return True
    for key in ("open","high","low","close","volume","timestamp"):
        arr = d.get(key, [])
        if isinstance(arr, list) and len(arr) > 0:
            return False
    return True

def zip_candles(d: dict) -> pd.DataFrame:
    """Convert Dhan arrays -> DataFrame with IST index. Handles empty safely."""
    if _is_empty_payload(d):
        return pd.DataFrame(columns=["open","high","low","close","volume"])
    cols = ["open","high","low","close","volume","timestamp"]
    n = min(len(d.get(c, [])) for c in cols if c in d)
    if n == 0:
        return pd.DataFrame(columns=["open","high","low","close","volume"])
    df = pd.DataFrame({c: d[c][:n] for c in cols})
    # Dhan timestamps are epoch seconds (UTC). Make them timezone-aware then convert to IST.
    dt = pd.to_datetime(df["timestamp"], unit="s", utc=True).dt.tz_convert(IST)
    df = df.assign(datetime=dt).set_index("datetime").drop(columns=["timestamp"])
    # Numeric coercion
    for c in ["open","high","low","close","volume"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df = df.dropna(subset=["open","high","low","close"]).sort_index()
    return df

def get_daily_history(securityId: str, start_date, end_date_non_inclusive) -> pd.DataFrame:
    """/charts/historical (daily). Dhan's toDate is NON-INCLUSIVE."""
    payload = {
        "securityId": str(securityId),
        "exchangeSegment": "NSE_EQ",
        "instrument": "EQUITY",
        "expiryCode": 0,
        "oi": False,
        "fromDate": start_date.strftime("%Y-%m-%d"),
        "toDate": end_date_non_inclusive.strftime("%Y-%m-%d")
    }
    data = _post("/charts/historical", payload)
    return zip_candles(data)

def get_intraday_1m(securityId: str, from_dt_local: datetime, to_dt_local: datetime) -> pd.DataFrame:
    """/charts/intraday (1-min). Returns empty df if API has nothing for that period."""
    payload = {
        "securityId": str(securityId),
        "exchangeSegment": "NSE_EQ",
        "instrument": "EQUITY",
        "interval": "1",
        "oi": False,
        "fromDate": from_dt_local.strftime("%Y-%m-%d %H:%M:%S"),
        "toDate":   to_dt_local.strftime("%Y-%m-%d %H:%M:%S"),
    }
    data = _post("/charts/intraday", payload)
    return zip_candles(data)

# ---- Indicators -----------------------------------------------------------
def rsi(series: pd.Series, period: int = 14) -> pd.Series:
    """Wilder's RSI(14) with EWM smoothing; safe on short series."""
    if len(series) < 2:
        return pd.Series([np.nan]*len(series), index=series.index)
    delta = series.diff()
    up = np.where(delta > 0, delta, 0.0)
    down = np.where(delta < 0, -delta, 0.0)
    roll_up = pd.Series(up, index=series.index).ewm(alpha=1/period, adjust=False).mean()
    roll_down = pd.Series(down, index=series.index).ewm(alpha=1/period, adjust=False).mean()
    with np.errstate(divide='ignore', invalid='ignore'):
        rs = roll_up / roll_down.replace(0, np.nan)
        r = 100 - (100 / (1 + rs))
    return r

def add_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """Adds MA 20/50/100/200 and RSI(14) if possible (keeps NaNs for too-short history)."""
    out = df.copy()
    for n in [20, 50, 100, 200]:
        out[f"MA{n}"] = out["close"].rolling(n, min_periods=1).mean()
    out["RSI14"] = rsi(out["close"], 14)
    return out

# ---- Resampling with partial last candle ---------------------------------
def _aggregate_partial(df_1m: pd.DataFrame) -> pd.Series:
    """Aggregate intraday 1m into OHLCV for the partial last period. Returns None if empty."""
    if df_1m is None or df_1m.empty:
        return None
    return pd.Series({
        "open": df_1m["open"].iloc[0],
        "high": df_1m["high"].max(),
        "low":  df_1m["low"].min(),
        "close":df_1m["close"].iloc[-1],
        "volume": df_1m["volume"].sum()
    })

def resample_to(df_daily: pd.DataFrame, chart_type: str, intraday_partial: pd.DataFrame) -> pd.DataFrame:
    """
    Resample daily to the requested timeframe.
    If intraday_partial is available, replace the last period with a partial candle up to the given time.
    All branches handle empty inputs safely.
    """
    if df_daily is None or df_daily.empty:
        # No history at all -> nothing to resample
        return pd.DataFrame(columns=["open","high","low","close","volume"])

    chart_type = (chart_type or "").strip().lower()

    if chart_type == "daily":
        df = df_daily.copy()
        part = _aggregate_partial(intraday_partial)
        if part is not None:
            # Use the date of the partial last bar
            day = intraday_partial.index[-1].date()
            idx = IST.localize(datetime(day.year, day.month, day.day, 15, 30))
            # Remove any existing daily candle for that day (if present) and insert partial
            df = df[df.index.date != day]
            partial_df = pd.DataFrame(part).T
            partial_df.index = [idx]
            df = pd.concat([df, partial_df]).sort_index()
        return df

    elif chart_type == "weekly":
        weekly = df_daily.resample("W-FRI").agg({
            "open":"first","high":"max","low":"min","close":"last","volume":"sum"
        }).dropna(how="any")
        part = _aggregate_partial(intraday_partial)
        if part is not None and not weekly.empty:
            # Compute combined (completed days of this week + intraday so far)
            last_dt = intraday_partial.index[-1]
            start_of_week = (last_dt - timedelta(days=last_dt.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)
            start_of_week = IST.localize(start_of_week)
            done_days = df_daily[(df_daily.index >= start_of_week) & (df_daily.index.date < last_dt.date())]

            open_price = done_days["open"].iloc[0] if not done_days.empty else intraday_partial["open"].iloc[0]
            high_price = max(done_days["high"].max() if not done_days.empty else -np.inf, part["high"])
            low_price  = min(done_days["low"].min()  if not done_days.empty else  np.inf, part["low"])
            close_price= part["close"]
            vol_sum    = (done_days["volume"].sum() if not done_days.empty else 0) + part["volume"]

            week_end = (pd.Timestamp(last_dt).tz_convert(IST)).normalize() + pd.offsets.Week(weekday=4)  # Friday
            idx = week_end + pd.Timedelta(hours=15, minutes=30)  # week_end already tz-aware

            # Replace the current week with the new partial
            if len(weekly) > 0:
                weekly = weekly.iloc[:-1]
            partial_df = pd.DataFrame({"open":[open_price],"high":[high_price],"low":[low_price],"close":[close_price],"volume":[vol_sum]}, index=[idx])
            weekly = pd.concat([weekly, partial_df]).sort_index()
        return weekly

    elif chart_type == "monthly":
        monthly = df_daily.resample("M").agg({
            "open":"first","high":"max","low":"min","close":"last","volume":"sum"
        }).dropna(how="any")
        part = _aggregate_partial(intraday_partial)
        if part is not None and not monthly.empty:
            last_dt = intraday_partial.index[-1]
            start_month = (pd.Timestamp(last_dt).tz_convert(IST)).normalize().replace(day=1)
            done_days = df_daily[(df_daily.index >= start_month) & (df_daily.index.date < last_dt.date())]

            open_price = done_days["open"].iloc[0] if not done_days.empty else intraday_partial["open"].iloc[0]
            high_price = max(done_days["high"].max() if not done_days.empty else -np.inf, part["high"])
            low_price  = min(done_days["low"].min()  if not done_days.empty else  np.inf, part["low"])
            close_price= part["close"]
            vol_sum    = (done_days["volume"].sum() if not done_days.empty else 0) + part["volume"]

            month_end = (pd.Timestamp(last_dt).tz_convert(IST)).normalize() + pd.offsets.MonthEnd(0)
            idx = month_end + pd.Timedelta(hours=15, minutes=30)  # month_end already tz-aware

            if len(monthly) > 0:
                monthly = monthly.iloc[:-1]
            partial_df = pd.DataFrame({"open":[open_price],"high":[high_price],"low":[low_price],"close":[close_price],"volume":[vol_sum]}, index=[idx])
            monthly = pd.concat([monthly, partial_df]).sort_index()
        return monthly

    else:
        # Unknown type -> default to daily (no partial)
        return df_daily.copy()

# ---- Plotting helpers -----------------------------------------------------
def _pad_right(df: pd.DataFrame, n_steps: int = 6) -> pd.DataFrame:
    """
    Add a few empty (NaN) time steps to the right so there is whitespace
    after the last candle. Works for daily/weekly/monthly or irregular indices
    by estimating a typical step from the last two rows; if unknown, uses 1 day.
    """
    if df is None or df.empty or len(df.index) < 2:
        return df

    idx = df.index
    # Estimate a "step" between last two timestamps (fallback = 1 day)
    try:
        step = idx[-1] - idx[-2]
        if step <= pd.Timedelta(0):
            step = pd.Timedelta(days=1)
    except Exception:
        step = pd.Timedelta(days=1)

    # Generate future timestamps (timezone-aware, same tz as index)
    fut = [idx[-1] + (i * step) for i in range(1, n_steps + 1)]
    pad = pd.DataFrame(
        np.nan,
        index=pd.DatetimeIndex(fut, tz=idx.tz),
        columns=["open", "high", "low", "close", "volume"]
    )
    return pd.concat([df, pad])

# ---- Plotting -------------------------------------------------------------
def make_premium_chart(df: pd.DataFrame, meta: dict, save_path: str):
    """Plot with candles, volume, RSI and MAs. Meets layout + CMP requirements."""
    if df is None or df.empty or len(df) == 0:
        raise ValueError("No data to plot.")

    # Right-side whitespace for aesthetics (pad ONLY the plotting copy)
    df_plot = df[["open","high","low","close","volume"]].copy()
    df_plot = _pad_right(df_plot, n_steps=6)

    # Align indicator columns to the padded index (so lengths match)
    # This is the key fix for the shape mismatch.
    df_aligned = df.reindex(df_plot.index)

    # ---- Moving average colors (distinct & readable) ----
    ma_colors = {
        "MA20":  "#1f77b4",   # blue
        "MA50":  "#ff7f0e",   # orange
        "MA100": "#2ca02c",   # green
        "MA200": "#d62728",   # red
    }

    # Build addplots for MAs (use df_aligned so lengths match df_plot)
    ap = []
    for c in ["MA20","MA50","MA100","MA200"]:
        if c in df_aligned.columns and df_aligned[c].notna().sum() >= 2:
            ap.append(mpf.make_addplot(df_aligned[c], panel=0, type='line', width=1.2, color=ma_colors[c]))

    # RSI panel if available (also from aligned df)
    have_rsi = ("RSI14" in df_aligned.columns and df_aligned["RSI14"].notna().sum() >= 2)
    if have_rsi:
        ap.append(mpf.make_addplot(df_aligned["RSI14"], panel=2, type='line', ylabel='RSI(14)', ylim=(0,100)))

    # ---- Style: price axis on RIGHT ----
    mc = mpf.make_marketcolors(up='g', down='r', edge='inherit', wick='inherit', volume='inherit')
    s  = mpf.make_mpf_style(marketcolors=mc, gridstyle='-', gridcolor='#e8e8e8', y_on_right=True)

    # ---- Draw chart ----
    fig, axes = mpf.plot(
        df_plot,
        type='candle',
        style=s,
        addplot=ap,
        volume=True,
        panel_ratios=(6,2,2) if have_rsi else (6,2),
        returnfig=True,
        figsize=(14,7),
        datetime_format='%d %b %y',
        tight_layout=True
    )

    ax_price = axes[0]
    ax_price.yaxis.set_ticks_position('right')
    ax_price.yaxis.tick_right()

    # Last real (non-NaN) close and its timestamp from ORIGINAL df (not padded)
    last_ts = df.index[-1]
    last_close = float(df["close"].iloc[-1])
    last_ts_str = last_ts.astimezone(IST).strftime('%a %d %b %y • %H:%M:%S')

    # X-axis label explicitly mentioning last candle's closing date/time
    ax_price.set_xlabel(f"Last (running) candle close: {last_ts_str}", fontsize=10)

    # ---- Header: Ticker line ----
    ax_price.text(
        0.01, 0.98,
        f"{meta.get('SHORT NAME','')}  •  {meta.get('CHART TYPE','')}  •  {meta.get('EXCHANGE','')}",
        transform=ax_price.transAxes, ha='left', va='top', fontsize=12, fontweight='bold'
    )

    # ---- MA legend box (with color swatches) just below the header ----
    legend_lines = []
    legend_labels = []
    for c in ["MA20","MA50","MA100","MA200"]:
        if c in df_aligned.columns:
            line, = ax_price.plot([], [], lw=2, color=ma_colors[c])  # dummy for legend
            legend_lines.append(line)
            legend_labels.append(c)
    if legend_lines:
        leg = ax_price.legend(
            legend_lines, legend_labels,
            loc='upper left', bbox_to_anchor=(0.006, 0.90),
            frameon=True, framealpha=0.9, borderpad=0.6, fontsize=9
        )
        try:
            leg.get_frame().set_boxstyle("Round,pad=0.3,rounding_size=2")
        except Exception:
            pass  # some backends don’t support rounded boxstyle

    # ---- Horizontal CMP line at last_close (dashed), labelled with CMP + datetime ----
    ax_price.axhline(last_close, linestyle='--', linewidth=1.1)

    # Place CMP label near the RIGHT padding region
    ax_price.annotate(
        f"CMP: {last_close:.2f}\n{last_ts_str}",
        xy=(df_plot.index[-1], last_close),  # far right (padded index)
        xytext=(-10, 10), textcoords='offset points',
        ha='right', va='bottom',
        bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.85)
    )

    # Small bubble at the last REAL candle
    ax_price.annotate(
        f"{last_close:.2f}",
        xy=(df.index[-1], last_close),
        xytext=(6, -18), textcoords='offset points',
        ha='left', va='top',
        bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="lightgray", alpha=0.8)
    )

    # RSI guides if panel exists
    if have_rsi and len(axes) >= 3:
        ax_rsi = axes[2]
        ax_rsi.axhline(70, linestyle=':', linewidth=0.8)
        ax_rsi.axhline(30, linestyle=':', linewidth=0.8)

    fig.savefig(save_path, dpi=150)
    plt.close(fig)




# ---- Pipeline -------------------------------------------------------------
def main():
    # 1) Find dynamic folder in input.csv (column containing "Folder Path")
    if not os.path.exists("input.csv"):
        raise FileNotFoundError("input.csv not found")
    df_in = pd.read_csv("input.csv")
    folder_col = [c for c in df_in.columns if "folder" in c.lower() and "path" in c.lower()]
    if not folder_col:
        raise ValueError("Could not find a 'Folder Path' column in input.csv")
    dynamic_folder = str(df_in[folder_col[0]].dropna().astype(str).iloc[0]).strip().strip('"\'' )

    if not os.path.isdir(dynamic_folder):
        raise NotADirectoryError(f"Folder from input.csv not found: {dynamic_folder}")

    charts_dir = os.path.join(dynamic_folder, "Charts")
    os.makedirs(charts_dir, exist_ok=True)

    # 2) Read stocks_with_analysis.csv
    swa_path = os.path.join(dynamic_folder, "stocks_with_analysis.csv")
    df = pd.read_csv(swa_path)

    # Normalize header names (spaces/case)
    def norm_col(x): return x.strip().upper().replace("\xa0", " ")
    df.columns = [norm_col(c) for c in df.columns]

    required = ["STOCK NAME","STOCK SYMBOL","LISTED NAME","SHORT NAME","SECURITY ID","EXCHANGE","INSTRUMENT","SEGMENT","START TIME","DATE","CMP","CHART TYPE","ANALYSIS"]
    for c in required:
        if c not in df.columns:
            raise KeyError(f"Missing column in stocks_with_analysis.csv: {c}")

    out_rows = []

    # 3) Iterate rows
    for idx, row in df.iterrows():
        try:
            security_id = str(row["SECURITY ID"]).strip()
            short_name  = str(row["SHORT NAME"]).strip()
            exchange    = "NSE"  # fixed display
            chart_type  = str(row["CHART TYPE"]).strip().title()  # Daily/Weekly/Monthly

            # Target timestamp = DATE + START TIME in IST
            date_obj = parse_date(str(row["DATE"]).strip())
            h, m, s = parse_time(str(row["START TIME"]).strip())
            end_dt_local = IST.localize(datetime(date_obj.year, date_obj.month, date_obj.day, h, m, s))

            # Historical window: last 8 months (toDate is non-inclusive -> +1 day)
            start_hist = (date_obj - relativedelta(months=8))
            end_hist_non_inclusive = date_obj + timedelta(days=1)

            # Fetch historical daily
            daily = get_daily_history(security_id, start_hist, end_hist_non_inclusive)

            # Fetch intraday (market open 09:15 -> end time). If non-trading day or no data, intraday will be empty (handled)
            market_open = IST.localize(datetime(date_obj.year, date_obj.month, date_obj.day, 9, 15, 0))
            if end_dt_local <= market_open:
                # if the requested time is before open, don't query intraday slice
                intraday = pd.DataFrame(columns=["open","high","low","close","volume"])
            else:
                intraday = get_intraday_1m(security_id, market_open, end_dt_local)

            # Build final timeframe
            df_tf = resample_to(daily, chart_type, intraday)

            if df_tf.empty:
                raise ValueError("API returned no candles for this SECURITY ID / time window.")

            # Add indicators
            df_tf = add_indicators(df_tf)

            # Plot & save
            fname = f"{security_id}_{chart_type}_{date_obj.strftime('%Y%m%d')}_{h:02d}{m:02d}{s:02d}.png"
            save_path = os.path.join(charts_dir, fname)
            meta = {"SHORT NAME": short_name, "CHART TYPE": chart_type, "EXCHANGE": exchange}
            make_premium_chart(df_tf, meta, save_path)

            # Collect output row
            out_row = {c: row.get(c, "") for c in required}
            out_row["CHART PATH"] = save_path
            out_rows.append(out_row)
            print(f"[{idx+1}/{len(df)}] Saved {save_path}")

        except Exception as e:
            print(f"[{idx+1}] ERROR for SECURITY ID {row.get('SECURITY ID')}: {e}")
            # Append row with empty chart path so output CSV still aligns with inputs
            out_row = {c: row.get(c, "") for c in required}
            out_row["CHART PATH"] = ""
            out_rows.append(out_row)

    # 4) Write output CSV with CHART PATH column
    out_df = pd.DataFrame(out_rows)
    out_path = os.path.join(dynamic_folder, "stocks_with_chart.csv")
    out_df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"\n✅ Done. Output saved to: {out_path}")

if __name__ == "__main__":
    main()
