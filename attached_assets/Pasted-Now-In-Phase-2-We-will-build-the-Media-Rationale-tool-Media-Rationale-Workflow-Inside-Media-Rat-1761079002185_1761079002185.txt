Now In Phase 2 We will build the Media Rationale tool. 
Media Rationale Workflow:
Inside Media Rationale, users can provide a YouTube URL and click Fetch Video.
When a valid URL is entered, fetch youtube video using yt dlp runs automatically to fetch the video metadata, including:
•	Video Title
•	Channel name
•	Channel logo (get logo path from channels database )
•	Upload date  (YYYY-MM-DD)
•	and time(24 hrs format)
•	Video duration
Below this information, a Start Analysis button appears.
When clicked:
•	Creates a job process,
•	Stores all metadata for future steps, and
•	Initiates all 15 processing steps sequentially.
•	If any step failed user can restart any previously completed step . example if user click on step5 restart icon then all steps from step 5 will restart
•	Just setup input and output for each step with dummy placeholder code in each step, job creation, store job in database, store activity, for each step and create pipeline and manage job, exact python code for each step will generate later.

Step		Description	Input	Output
1	Download Audio
	Download Youtubevideo audio (yt-dlp)	Youtube URL	audio_16k_mono.wav

2	Download Captions
	Download Youtube  auto generated captions (JSON)	Youtube URL	captions.json

3	Transcribe Audio
	Transcribe audio using AssemblyAI with speaker Recognition
	audio_16k_mono.wav
	transcript.csv
transcript.txt
4	Merge Transcripts
	Merge Youtube auto generated captions.json & transcript. Replace assembly ai transcripted text with youtube caption	captions.json
transcript.csv
	final_transcript.txt

5	Translate to English
	Translate to English (Google Translate API)	final_transcript.txt
	transcript_english.txt

6	Detect Speakers
	Detect speakers using (OpenAI), who is Anchor and who is pradip	transcript_english.txt
	detected_speakers.txt

7	Filter Transcription
	Keep only Anchor & Pradip Transcription lines	detected_speakers.txt
transcript_english.txt
	filtered_transcription.txt

8	Extract Stock Mentions
	Extract stock  mentions and discussed by Pradip , with stock symbols and time, using OPEN AI	filtered_transcription.txt
detected_speakers.txt
	extracted_stocks.csv
9	Map Master File
	Match stock symbol with master file (api-scrip-master.csv) to get securities id, exchange etc	extracted_stocks.csv	mapped_master_file.csv
10	Convert Timestamps
	Convert timestamps to actual time/date	mapped_master_file.csv	stocks_with_date_time.csv
11	Fetch CMP
	Fetch CMP from Dhan API	stocks_with_date_time.csv	stocks_with_cmp.csv
12	Extract Analysis
	Use OpenAI to extract analysis text given by Pradip speaker	stocks_with_cmp.csv
detected_speakers.txt
filtered_transcription.txt
stocks_with_cmp.csv	stocks_with_analysis.csv
13	Generate Charts
	Fetch candlestick stock chart (Dhan API)	stocks_with_analysis.csv
Dhan API from Database	stocks_with_chart.csv

14	Generate PDF
	Generate final branded PDF (ReportLab)	stocks_with_chart.csv
Channel logo from database
PDF Template Data from database
	final_rationale_report.pdf
15	Save / Save & Sign & Log
	Upload signed PDF + update logs	Upload signed file 	Store in db and show in iframe


Suggested File / module layout (backend) for Media Rationale
─ pipeline/
│  ├─ fetch_video_data.py
│  ├─ step01_download_audio.py
│  ├─ step02_download_captions.py
│  ├─ step03_assemblyai_transcribe.py
│  ├─ step04_merge_transcripts.py
│  ├─ step05_translate.py
│  ├─ step06_speaker_detect.py
│  ├─ step07_filter_transcription.py
│  ├─ step08_extract_stock_mentions.py
│  ├─ step09_map_master_file.py
│  ├─ step10_convert_timestamp.py
│  ├─ step11_fetch_cmp.py
│  ├─ step12_extract_analysis.py
│  ├─ step13_generate_charts.py
│  ├─ step14_generate_pdf.py
│  ├─ step15_save_and_sign_log.py

Activity Log
The Activity Log includes filters:
•	By Tool: Media Rationale / Premium Rationale / Manual Rationale
•	By User Name
•	By Status: All Activities / Job Started / Job Completed / Job Failed / Login / Logout
•	By Date Range
Each activity entry displays:
•	User avatar and name
•	Status
•	Tool used
•	Job name (e.g., “Started new Media Rationale job for YouTube video”)
•	Job ID
•	Date and time (e.g., “20h ago, 03:55 PM”)

Saved Rationale
The Saved Rationale section stores all generated rationales and includes filters:
•	By Tool (all three tools)
•	By Channel Name (channels listed in Manage Channel)
•	By Date Range
All Saved Rationale has 
•	Youtube Video Title
•	Channel Name
•	Used Tool
•	Video Date
•	Job ID
•	View progress Download Unsigned (generated in step 14) PDF
•	Upload Signed PDF
•	Download Signed PDF
•	Show When Signed PDF Uploaded

First understand how my frontend is working for Media Rationale then make a detailed structure for backend , database scheme and then make my tool work, no mock data, replace with actual.
Strictly Do not change my frontend design, work flow/ animations etc.
